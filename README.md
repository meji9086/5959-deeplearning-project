# 59ï¸âƒ£59ï¸âƒ£-deeplearning-project        
**ğŸ¦ Likelion AI SCHOOL7 ğŸ‘¶ğŸ¤± ìœ¼ìƒ¤ìœ¼ìƒ¤íŒ€3 9ì¡° ì˜¤9ï¸âƒ£ì˜¤9ï¸âƒ£ íŒ€**    


#### ğŸ‘¨â€ğŸ‘©â€ğŸ‘§â€ğŸ‘¦ Team Info.    
|name|github|velog&blog|                       
|:---:|:---:|:---:|                                        
|<span style="color:blue">[ê¹€ì˜ˆì§€ğŸ‘‘](https://github.com/meji9086)</span>|<a href="https://github.com/meji9086"><img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=White"/>|<a href="https://blog.naver.com/meji9086"><img src="https://img.shields.io/badge/blog-09B3AF?style=flat-square&logo=Storyblok&logoColor=white"/>|                                    
|<span style="color:blue">[ì´ì •ì€](https://github.com/LJEDD2)</span>|<a href="https://github.com/hooun"><img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=White"/>|<a href="https://blog.naver.com/charzim0611"><img src="https://img.shields.io/badge/blog-09B3AF?style=flat-square&logo=Storyblok&logoColor=white"/>|                  
|<span style="color:blue">[ì¡°ì˜ˆìŠ¬](https://github.com/seul1230)</span>|<a href="https://github.com/tvn123"><img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=White"/>|<a href="https://seul1230.github.io/"><img src="https://img.shields.io/badge/blog-09B3AF?style=flat-square&logo=Storyblok&logoColor=white"/>|                    
|<span style="color:blue">[ì„ì¢…ìš°](https://github.com/imngooh)</span>|<a href="https://github.com/dkssudgb"><img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=White"/>|<a href="https://velog.io/@im_ngooh"><img src="https://img.shields.io/badge/velog-20C997?style=flat-square&logo=velog&logoColor=white"/>|            
|<span style="color:blue">[ê¶Œíƒœìœ¤](https://github.com/taeyoon94)</span>|<a href="https://github.com/taeyoon94"><img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=White"/>|<a href="https://github.com/taeyoon94"><img src="https://img.shields.io/badge/github-181717?style=flat-square&logo=github&logoColor=White"/>          

#### ğŸ’¡ Project Info.         
|number|title|link|bestscore|
|:-:|:----:|:----:|:-:|         
|1|ğŸ¥¬ Prediction of bok choy growth|[https://dacon.io/competitions/official/235961/overview/description](https://dacon.io/competitions/official/235961/overview/description)|private mse 17.53|         
|2|ğŸ˜· Face Mask Classification|[https://www.kaggle.com/datasets/dhruvmak/face-mask-detection](https://www.kaggle.com/datasets/dhruvmak/face-mask-detection)|accuracy 0.97|        
|3|ğŸ“ Sentences type Classification|[https://dacon.io/competitions/official/236037/overview/description](https://dacon.io/competitions/official/236037/overview/description)|private accuracy 0.7559|        

## 1. ğŸ¥¬ Prediction of bok choy growth ğŸ¥¬
![image](https://user-images.githubusercontent.com/72390138/205493584-af95700c-c420-4f95-a5fc-d1c05bb27bc7.png)      

ğŸ† dacon AI ê²½ì§„ëŒ€íšŒ : **ì²­ê²½ì±„ ì„±ì¥ë¥  ì˜ˆì¸¡í•˜ê¸°**                    
ì£¼ì†Œ : [https://dacon.io/competitions/official/235961/overview/description](https://dacon.io/competitions/official/235961/overview/description)        
  
ğŸ“œ notion : https://www.notion.so/MINI5-AI-b031d68247e24a30b192b24c522284d1
  
### ğŸ“ƒ summary     
<img src="https://user-images.githubusercontent.com/72390138/205493735-e21c9908-44e8-45e9-8a9c-f3942f203fa7.png" weight="350" height="350">        
4ì°¨ ì‚°ì—…í˜ëª… ì‹œëŒ€ë¥¼ ë§ì•„ ë†ì—… ë¶„ì•¼ì—ì„œë„ AI ê¸°ìˆ ì´ ë„ë¦¬ ì‚¬ìš©ë˜ì–´ IT ê¸°ìˆ ì„ ë™ì›í•œ ìŠ¤ë§ˆíŠ¸íŒœ ë“± ë”ìš± íš¨ìœ¨ì ì¸ ì‘ë¬¼ ì¬ë°°ê°€ ê°€ëŠ¥í•´ì§€ê³  ìˆìŠµë‹ˆë‹¤. ì‘ë¬¼ì˜ íš¨ìœ¨ì ì¸ ìƒìœ¡ì„ ìœ„í•œ ìµœì ì˜ í™˜ê²½ì„ ë„ì¶œí•œë‹¤ë©´ ì‹ë¬¼ ì¬ë°°ì— í° ë„ì›€ì´ ë  ê²ƒì´ë©°, ì²­ê²½ì±„ ë¿ë§Œ ì•„ë‹Œ ëª¨ë“  ì‘ë¬¼ ì¬ë°°ìœ¨ì´ ì¢‹ì•„ì§ˆ ê²ƒì…ë‹ˆë‹¤. ë¯¸ë˜ì˜ ì‘ë¬¼ ì¬ë°°ì—ì„œëŠ” ì´ ë°ì´í„°ë¥¼ ê°€ì§€ê³  ì¸ê³µì§€ëŠ¥ì„ ì´ìš©í•˜ì—¬ ì‘ë¬¼ë³„ ë§ì¶¤í˜• ì†”ë£¨ì…˜ì„ ë†ì—…ì¸ë“¤ì´ í¸ë¦¬í•˜ê³  ì¹œê·¼í•˜ê²Œ ìƒí™œ ì†ì—ì„œ í™œìš©í•˜ëŠ” ì²« ê±¸ìŒì„ ë‚´ë”›ì„ ìˆ˜ ìˆì„ ê²ƒì…ë‹ˆë‹¤.      
 
  
ë”°ë¼ì„œ, **ì¸ê³µì§€ëŠ¥(AI)ì„ í™œìš©í•˜ì—¬ êµ­ë‚´ ê³ ìœ  ì‹ë¬¼ ìì›ì—ì„œ ìœ ìš©í•œ ì²œì—°ë¬¼ ì†Œì¬ë¥¼ íƒìƒ‰í•˜ê³ , ê·¸ íš¨ëŠ¥ê³¼ í™œì„± ë“±ì— ëŒ€í•´ ì—°êµ¬í•˜ëŠ” ê²ƒì´ ëª©í‘œ**ì…ë‹ˆë‹¤.     
ì‹¤ì œ AIë¥¼ ì´ìš©í•œ ì‘ë¬¼ì„ ì¬ë°°í•˜ëŠ” ìŠ¤ë§ˆíŠ¸íŒœê³¼ ê°™ì€ ê³³ì— ìœ ìš©í•˜ê²Œ ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤.      
  
  
### ğŸ—‚ Data info.     
**dacon ì²­ê²½ì±„ ì˜ˆì¸¡ ë°ì´í„°** : [https://dacon.io/competitions/official/235961/data](https://dacon.io/competitions/official/235961/data)   

**ğŸ“ train input dataset[folder]**       
![image](https://user-images.githubusercontent.com/72390138/205494867-68e0c49a-3740-4fe4-8812-da281ace0524.png)    
ì´ 58ê°œ ì²­ê²½ì±„ ì¼€ì´ìŠ¤ë¥¼ ê° ì²­ê²½ì±„ ì¼€ì´ìŠ¤ ë³„ í™˜ê²½ ë°ì´í„°(1ë¶„ ê°„ê²©)ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ      

**ğŸ“ train target dataset[folder]**                  
<img src="https://user-images.githubusercontent.com/72390138/205494955-e4752ba6-3a90-41de-a1ee-ec2929ea8dd6.png" weight="300" height="500">     
ì´ 58ê°œ ì²­ê²½ì±„ ì¼€ì´ìŠ¤ë¥¼ rate columnì˜ ê° ì²­ê²½ì±„ ì¼€ì´ìŠ¤ ë³„ ì ë©´ì  ì¦ê°ë¥ (1ì¼ ê°„ê²©)ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ       

**ğŸ“‚ train(input+target) shape**                   
train(input+target) (1813, 43)         
test(input+target) (195, 43)            
  
  
### ğŸ“Š Visualization        
1ï¸âƒ£ ë‚´ë¶€ì˜¨ë„ê´€ì¸¡ì¹˜, ë‚´ë¶€ìŠµë„ê´€ì¸¡ì¹˜, ì´ì¶”ì •ê´‘ëŸ‰, ì›”ë³„ rate        
![image](https://user-images.githubusercontent.com/72390138/205497279-d59cb01a-a52e-44f7-9cef-c34381f8fcfd.png)              

2ï¸âƒ£ ì ìƒ‰, ì²­ìƒ‰, ë°±ìƒ‰, ì´ì¶” ì¶”ì •ê´‘ëŸ‰ ë³„ rate
![image](https://user-images.githubusercontent.com/72390138/205497255-0030b727-3f14-4c07-b22b-806a05334616.png)             
ë°±ìƒ‰ê³¼ ì´ì¶”ëŠ” 100ì—ì„œ, ì ìƒ‰ê³¼ ì²­ìƒ‰ì€ 0ì—ì„œ ì„±ì¥ë¥ ì´ ë†’ë‹¤.     
  
3ï¸âƒ£ ECì™€ CO2ì˜ ëƒ‰ë°©ìƒíƒœ       
![image](https://user-images.githubusercontent.com/72390138/205496256-fe545a8c-16b8-4644-a339-030a2d05f271.png)       
ECê´€ì¸¡ì¹˜ê°€ í´ìˆ˜ë¡ ëƒ‰ë°©ìƒíƒœëŠ” ì ì—ˆìœ¼ë©°, ë°˜ëŒ€ë¡œ ì‘ì„ìˆ˜ë¡ ëƒ‰ë°©ìƒíƒœëŠ” ë†’ì€ ê²ƒì„ í™•ì¸í•  ìˆ˜ ìˆë‹¤.   

4ï¸âƒ£ ê° CASE ë³„ ìë©´ì  ì¦ê°ë¥ (rate) ë³€í™”      
![image](https://user-images.githubusercontent.com/72390138/205496376-956636fd-c78d-433e-b690-bdb8764cfe71.png)      
ë¶„í¬ë¥¼ ì¼ì •í•˜ê²Œ ë§Œë“¤ê¸° ìœ„í•œ Scaling ê³¼ì •ì´ í•„ìš”í•¨ì´ ë³´ì˜€ë‹¤.          
  
 
### ğŸ” Modeling
ğŸ“Œ Scaling - RobustScaler      
```python      
from sklearn.preprocessing import RobustScaler        
rb = RobustScaler()         
train_X = rb.fit_transform(train_X)         
test_X = rb.transform(test_X)            
```
  
ğŸ“Œ Tensorflow    
```python
model = tf.keras.models.Sequential([
    tf.keras.layers.Dense(units=128, input_shape=[input_shape]),
    tf.keras.layers.Dense(128, activation='selu'),
    tf.keras.layers.Dropout(0.1),
    tf.keras.layers.Dense(1)
])
  
optimizer = tf.keras.optimizers.RMSprop(0.001)     
  
model.compile(optimizer=optimizer, 
              loss=["mae", "mse"], 
              metrics=["mae", "mse"])
```

ğŸ“Œ Pytorch     
```python      
linear1 = torch.nn.Linear(train_X.shape[1], 512, bias=True)
linear3 = torch.nn.Linear(512, 256, bias=True)
linear4 = torch.nn.Linear(256, 128, bias=True)
linear5 = torch.nn.Linear(128, 64, bias=True)
linear6 = torch.nn.Linear(64, 32, bias=True)
linear7 = torch.nn.Linear(32, 10, bias=True)
linear8 = torch.nn.Linear(10, 1, bias=True)

relu = torch.nn.ReLU()
dropout = torch.nn.Dropout(p=0.1)
  
model = torch.nn.Sequential(linear1,relu,
                            linear3,relu,
                            linear4, relu,
                            linear5, relu,
                            linear6, relu,
                            linear7, relu,
                            linear8).to(device)

# nn íŒ¨í‚¤ì§€ë¥¼ ì‚¬ìš©í•˜ì—¬ ëª¨ë¸ê³¼ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤.
loss_fn = torch.nn.MSELoss().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.0005)

# ê°€ì¤‘ì¹˜ ì´ˆê¸°í™” 
torch.nn.init.xavier_normal_(linear1.weight)
torch.nn.init.xavier_normal_(linear2.weight)
torch.nn.init.xavier_normal_(linear3.weight)
torch.nn.init.xavier_normal_(linear4.weight)
torch.nn.init.xavier_normal_(linear5.weight)
torch.nn.init.xavier_normal_(linear6.weight)
torch.nn.init.xavier_normal_(linear7.weight)
torch.nn.init.xavier_normal_(linear8.weight)     
  
Parameter containing:
tensor([[-0.1239,  0.3789, -0.2748,  0.2951,  0.0612,  0.2898,  0.2660, -0.4028,
         -1.1738,  0.6484]], requires_grad=True)        
```

ğŸ“Œ LSTM    
```python    
class BaseModel(nn.Module):
    def __init__(self):
        super(BaseModel, self).__init__() 
        self.lstm = nn.LSTM(input_size=train_X.shape[1], hidden_size=256, batch_first=True, bidirectional=False) # LSTM ë©”ëª¨ë¦¬ ì¶”ê°€ 
        self.dense = nn.Sequential(
            # nn.Linear(256, 10 , torch.nn.ReLU()),
            # Layer ì¶”ê°€ 
            nn.Linear(256, 128,  torch.nn.ReLU()),
            nn.Linear(128, 64, torch.nn.ReLU()),
            nn.Linear(64, 32,  torch.nn.ReLU()),
            nn.Linear(32, 10,  torch.nn.ReLU()),
            nn.Linear(10, 1)
        )
        self.dropout = nn.Dropout(0.2)
        
    def forward(self, x):
        hidden, _ = self.lstm(x)
        x = self.dropout(hidden)
        output = self.dense(hidden)
        return output
  
model = BaseModel()
model.eval() 
loss_fn = torch.nn.MSELoss().to(device)
optimizer = optim.Adam(model.parameters(), lr=0.0005)    
```
  
  
### ğŸ€ Submission & Score (mse)
ğŸ“ŒTensorflow      
public : 17.91, private : 17.53     
ğŸ“Œ Pytorch    
public : 19.2138, private : 18.009    
ğŸ“ŒLSTM      
public : 21.5578 / private 22.5213      

---

## 2. ğŸ˜· Face Mask Classification ğŸ˜·     
<img src="https://user-images.githubusercontent.com/72390138/206939017-352d4a33-79df-4d47-873c-4fefd40c5884.png" weight="350" height="190">        

ğŸ† Kaggle AI ê²½ì§„ëŒ€íšŒ : **ë§ˆìŠ¤í¬ ì°©ìš©/ë¯¸ì°©ìš© ë¶„ë¥˜**                    
ì£¼ì†Œ : [https://www.kaggle.com/datasets/dhruvmak/face-mask-detection](https://www.kaggle.com/datasets/dhruvmak/face-mask-detection)        
  
ğŸ“œ notion : https://www.notion.so/MINI6-Mask_or_No_Mask-Classification-a7d66cebd161444180e9024e13be2f98#35d0f4877a1f4aa3bd9a0719fc5bea2d     
ğŸ“Œ streamlit : https://seul1230-mask-classification-main-pqg0f0.streamlit.app/
ğŸ“Œ streamlit : https://imngooh-mini-streamlit-app-82wtn0.streamlit.app/
  
### ğŸ“ƒ summary     
<img src="https://user-images.githubusercontent.com/72390138/206940326-e4e4d101-7939-4072-8c9c-65f5e03734fa.png" weight="400" height="400">         
ì½”ë¡œë‚˜19 ë°”ì´ëŸ¬ìŠ¤ë¡œ ì¸í•œ ë§ˆìŠ¤í¬ ì°©ìš© ì˜ë¬´í™”í•˜ì˜€ì—ˆê³ , ê·¸ì— ë”°ë¥¸ ë§ˆìŠ¤í¬ ë¯¸ì°©ìš©ìì— ëŒ€í•œ ê³¼íƒœë¡œ ë¶€ê³¼ ëŒ€ìƒì— ì²˜í–ˆì—ˆë‹¤.     
ë§ˆìŠ¤í¬ ì°©ìš©ê³¼ ë¯¸ì°©ìš©ì˜ ë¶„ë¥˜ë¥¼ í†µí•´ ëª¨ë‹ˆí„°ë§í•˜ëŠ” ì¸ë ¥ì„ ê°ì†Œí™”í•˜ê³  ë§ˆìŠ¤í¬ ì°©ìš©ì˜ ì˜ë¬´í™”ë¥¼ ëŠë¼ê³  ì°©ìš©ë¥ ì„ ë†’ì´ê³ ì í•œë‹¤.    

### ğŸ—‚ Data info.  
**kaggle ë§ˆìŠ¤í¬ ì°©ìš© ì—¬ë¶€ ì´ë¯¸ì§€ ë°ì´í„°** : [https://www.kaggle.com/datasets/dhruvmak/face-mask-detection](https://www.kaggle.com/datasets/dhruvmak/face-mask-detection)   

**ğŸ“ with mask[folder]**       
<img src="https://user-images.githubusercontent.com/72390138/206941647-f46f60a9-3f55-492c-8430-a7e0bce5b8b6.png" weight="500" height="500">         
ì´ 220ê°œì˜ ë§ˆìŠ¤í¬ ì°©ìš©í•œ ì‚¬ëŒë“¤ì˜ ì´ë¯¸ì§€

**ğŸ“ without mask[folder]**                  
<img src="https://user-images.githubusercontent.com/72390138/206941671-6211b537-b270-45d3-8fc0-c0d6f1f7285f.png" weight="500" height="500">       
ì´ 220ê°œì˜ ë§ˆìŠ¤í¬ ë¯¸ì°©ìš©í•œ ì‚¬ëŒë“¤ì˜ ì´ë¯¸ì§€      

**ğŸ“‚ train/valid/test shape**                    
train_df (281, 2)          
val_df (71, 2)       
test_df (88, 2)        

### ğŸ“Š Visualization    
âœ… Target Ratio     
<img src="https://user-images.githubusercontent.com/72390138/206941876-1053e395-212a-43ff-b40f-f54566dab42f.png" weight="350" height="350">         

### ğŸ” Modeling         
**â­ Tensorflowë¥¼ ì´ìš©í•œ ëª¨ë¸ë§ â­**                
ğŸ“Œ Resnet152V       
```python
# imagenetìœ¼ë¡œ pre-trained ëœ ê°€ì¤‘ì¹˜ ê°’ ì ìš©
md = ResNet152V2(include_top=False, pooling='max', 
                  weights='imagenet', input_shape=(height, width, 3))
md.trainable=False

model = models.Sequential()
model.add(md)
model.add(layers.Dense(1, activation = 'sigmoid'))

model.compile(loss='binary_crossentropy', 
              optimizer='adam', 
              metrics=['accuracy'])
              
early_stop = EarlyStopping(patience=5)

history = model.fit(train_datagen, epochs=20, 
                    validation_data=val_datagen,
                    validation_steps=len(val_datagen),
                    callbacks = [early_stop])         
```   
<img src="https://user-images.githubusercontent.com/72390138/206942373-bc752360-e652-4c91-be5f-ba8d5addb118.png" weight="250" height="250">         


ğŸ“Œ VGG19      
```python
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten
from tensorflow.keras.applications import vgg19

vgg = vgg19.VGG19(
    include_top = False,
    weights = 'imagenet',
    input_shape = (height, width, 3)
)

model = Sequential()
model.add(vgg)
model.add(Flatten())
model.add(Dense(1, activation = 'sigmoid'))

model.compile(
    optimizer = 'adam',
    loss = 'binary_crossentropy',
    metrics = ['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)

history = model.fit(
    train_dataset,
    epochs = 100,
    validation_data = valid_dataset,
    callbacks = [early_stop]
```        
<img src="https://user-images.githubusercontent.com/72390138/206942406-f0be43cf-3d94-42f6-9991-9a2c7fcd725c.png" weight="350" height="350">         
  
ğŸ“Œ DenseNet121       
```python
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten
from tensorflow.keras.applications import densenet

densenet = densenet.DenseNet121(
    include_top = False,
    weights = 'imagenet',
    input_shape = (height, width, 3),
    pooling = 'avg'
)

modeld = Sequential()
modeld.add(densenet)
modeld.add(Flatten())
modeld.add(Dense(1, activation = 'sigmoid'))

modeld.compile(
    optimizer = 'adam',
    loss = 'binary_crossentropy',
    metrics = ['accuracy']
)

from tensorflow.keras.callbacks import EarlyStopping

early_stop = EarlyStopping(monitor = 'val_loss', patience = 10)

history = modeld.fit(
    train_dataset,
    epochs = 100,
    validation_data = valid_dataset,
    callbacks = [early_stop]
)
```    
<img src="https://user-images.githubusercontent.com/72390138/206942427-2138ee68-d95b-4edc-8abb-39380b53a913.png" weight="350" height="350">          
  
### ğŸ€ Submission & Score
ğŸ“Œ Resnet152V  -> Best Score     
<img src="https://user-images.githubusercontent.com/72390138/206942588-a344bb5b-e72e-4909-b12d-777fbd5a6906.png" weight="350" height="450">         

ğŸ“Œ íŒ€ì›ë“¤ì˜ ì´ë¯¸ì§€ë¥¼ ì´ìš©í•œ ë§ˆìŠ¤í¬ ì°©ìš©/ë¯¸ì°©ìš© ì˜ˆì¸¡
<img src="https://user-images.githubusercontent.com/72390138/206942609-2b1b424c-a72c-498c-ae7e-71da416d8ec6.png" weight="500" height="550">         

---

## 3. ğŸ“ Sentences type Classification ğŸ“        
![image](https://user-images.githubusercontent.com/72390138/208331196-715359e9-52b9-43cf-b5e9-4c6793a98c16.png)    

ğŸ† dacon AI ê²½ì§„ëŒ€íšŒ : **ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜í•˜ê¸°**                    
ì£¼ì†Œ : [https://dacon.io/competitions/official/236037/overview/description](https://dacon.io/competitions/official/236037/overview/description)        
  
ğŸ“œ notion : https://www.notion.so/Dacon-AI-54fe914d79584be2a7bd9404ee6fa9a5
  
### ğŸ“ƒ summary     
<img src="https://user-images.githubusercontent.com/72390138/208331552-42328ba1-475f-4332-9fe5-74658283ce4f.png" weight="400" height="400">               
í•˜ë£¨ ì¢…ì¼ í•œ ë§ˆë””ë„ í•˜ì§€ ì•ŠëŠ” ë‚ ì€ ìƒìƒí•  ìˆ˜ ìˆì§€ë§Œ, í•œ ê¸€ìë„ ì½ì§€ ì•ŠëŠ” ë‚ ì€ ìƒìƒí•  ìˆ˜ ì—†ëŠ” ê²ƒì²˜ëŸ¼ ìš°ë¦¬ëŠ” ìˆ˜ë§ì€ ë¬¸ì¥ê³¼ ê¸€ ì†ì— ë‘˜ëŸ¬ì‹¸ì—¬ ì‚´ê³  ìˆë‹¤.       
íŠ¹íˆë‚˜ ì½”ë¡œë‚˜19 ì´í›„, ìš°ë¦¬ ì‚¬íšŒì—ì„  ì˜¨ë¼ì¸ê³¼ ë¹„ëŒ€ë©´ ì†Œí†µì´ ì£¼ëœ êµë¥˜ ë°©ì‹ì´ ë˜ì—ˆë‹¤. ê·¸ë§Œí¼ ìš°ë¦¬ëŠ” ì´ì „ë³´ë‹¤ë„ ë” ë§ì€ ë¬¸ì¥ì„ ì½ê³  ì“°ë©° ì„¸ìƒê³¼ ì†Œí†µí•˜ê³  ìˆë‹¤.           
ì´ì²˜ëŸ¼ ìˆ˜ë§ì€ ê¸€ë“¤ì„ AI ëª¨ë¸ì„ í™œìš©í•´ í•™ìŠµí•˜ê³ , ë¹ ë¥´ê²Œ ë¶„ë¥˜í•  ìˆ˜ ìˆë‹¤ë©´ ìš°ë¦¬ëŠ” ë” ì •êµí•˜ê²Œ ë¶„ë¥˜ëœ ì •ë³´ë¥¼ ì–»ê³ , ì´ë¥¼ í†µí•´ ì–¸ì–´ê°€ ì“°ì´ëŠ” ëª¨ë“  ì˜ì—­ì—ì„œ ë³´ë‹¤ ì‚¬ìš©ì ì¹œí™”ì ì¸ ì„œë¹„ìŠ¤ë¥¼ ê²½í—˜í•  ìˆ˜ ìˆê²Œ ë  ê²ƒì´ë‹¤.      


ë”°ë¼ì„œ, í•œ ë°œ ë” ë‚˜ì•„ê°€ í•œêµ­ì–´ ì¸ê³µì§€ëŠ¥ ê¸°ìˆ  ê³ ë„í™”ì˜ ë°œíŒì„ ë§ˆë ¨í•  ìˆ˜ ìˆë„ë¡ ì°½ì˜ì ì¸ ë¬¸ì¥ ìœ í˜• ë¶„ë¥˜ AI ëª¨ë¸ì„ ë§Œë“œëŠ” ê²ƒì´ ëª©í‘œì´ë‹¤.     

### ğŸ—‚ Data info.     
**dacon ì²­ê²½ì±„ ì˜ˆì¸¡ ë°ì´í„°** : [https://dacon.io/competitions/official/236037/data](https://dacon.io/competitions/official/236037/data)    

**ğŸ“ train dataset**       
<img src="https://user-images.githubusercontent.com/72390138/208332994-75fab7bd-0a1c-48c2-9626-5de87625e60b.png" weight="400" height="400">          
ë¬¸ì¥ì— ë”°ë¥¸ ìœ í˜•, ê·¹ì„±, ì‹œì œ, í™•ì‹¤ì„±ì´ êµ¬ë¶„ë˜ì–´ ìˆìŒ (ì´ 72ê°œ ì¢…ë¥˜ì˜ Class ì¡´ì¬)           

**ğŸ“ train dataset**     
<img src="https://user-images.githubusercontent.com/72390138/208333183-925307ba-d173-4f4f-a62b-5a2f0d6becac.png" weight="300" height="350">       
ì´ 7090 ë¬¸ì¥ìœ¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŒ        

**ğŸ“‚ train/test shape**                   
train (16541, 7)         
test (7090, 2)             

### ğŸ“Š Visualization        
**1ï¸âƒ£ ê° labelì˜ ë¹ˆë„ìˆ˜ ì‹œê°í™”**                 
<img src="https://user-images.githubusercontent.com/72390138/208333478-daf842be-bde7-4413-be56-fe68cbf5ef59.png" weight="400" height="400">            
ê·¹ì„±, ìœ í˜•, í™•ì‹¤ì„±ì€ í•œ ê³³ìœ¼ë¡œ ì¹˜ìš°ì³ì§„ labelì´ ìˆë‹¤.     
ì´ì— ë”°ë¥¸ í•´ê²°ì±…ì„ ìƒê°í•´ì•¼ í•  ê²ƒì´ë‹¤.      

**2ï¸âƒ£ í•˜ë‚˜ë¡œ í†µí•©í•œ labelì˜ ë¹ˆë„ìˆ˜ ì‹œê°í™”**         
<img src="https://user-images.githubusercontent.com/72390138/208333756-bfa89cc9-b8bd-41ea-90c8-2b2bbcc4d2f6.png" weight="400" height="400">            
ê° í´ë˜ìŠ¤ ì‚¬ì´ì—ì„œ ë¶ˆê· í˜•ì´ ì¼ì–´ë‚¨ì„ ì•Œ ìˆ˜ ìˆë‹¤.      

### ğŸ” Modeling         
**ğŸ“Œ Tensorflow**    
```python
early_stop = EarlyStopping(monitor='val_loss', patience=5)
embedding_dim = 256

def Model(label):
    n_class = train_labels[label].shape[1]
    
    # ëª¨ë¸ ì •ì˜
    model = Sequential()
    model.add(Embedding(input_dim = 77426,
                        output_dim = embedding_dim,
                        input_length = 80))
   
    model.add(Bidirectional(LSTM(64, return_sequences=True)))
    model.add(Bidirectional(LSTM(64, return_sequences=True)))
    model.add(LSTM(64))
    
    model.add(Dense(64, activation = 'relu'))
    model.add(Dense(n_class, activation = 'softmax'))

    model.compile(optimizer = 'adam',
                  loss = 'categorical_crossentropy',
                  metrics = ['accuracy'])
    
    # ëª¨ë¸ ì„œë¨¸ë¦¬
    display(model.summary())

    # ëª¨ë¸ í”¼íŒ…
    history = model.fit(train_vec, train_labels[label], epochs = 100, validation_data = (val_vec, val_labels[label]), callbacks = [early_stop])
    df_hist = pd.DataFrame(history.history)

    print('*'*5, 'í•™ìŠµì™„ë£Œ', '*'*5)
    df_hist[['loss','val_loss']].plot()
    df_hist[['accuracy','val_accuracy']].plot()
    
    # ëª¨ë¸ í‰ê°€
    print('valid í‰ê°€ ê²°ê³¼')
    model.evaluate(val_vec, val_labels[label])

    # ì˜ˆì¸¡
    y_pred = model.predict(test_vec)
    y_predict = np.argmax(y_pred, axis = 1)
    return y_predict
```

**ğŸ“Œ pytorch**    
```python
class BaseModel(nn.Module):
    def __init__(self, input_dim=9351):
        super(BaseModel, self).__init__()
        self.feature_extract = nn.Sequential(
            nn.Linear(in_features=input_dim, out_features=1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(),
            nn.Linear(in_features=1024, out_features=1024),
            nn.BatchNorm1d(1024),
            nn.LeakyReLU(),
            nn.Linear(in_features=1024, out_features=512),
            nn.BatchNorm1d(512),
            nn.LeakyReLU(),
        )
        self.type_classifier = nn.Sequential(
            nn.Dropout(p=0.3),
            nn.Linear(in_features=512, out_features=4),
        )
        self.polarity_classifier = nn.Sequential(
            nn.Dropout(p=0.3),
            nn.Linear(in_features=512, out_features=3),
        )
        self.tense_classifier = nn.Sequential(
            nn.Dropout(p=0.3),
            nn.Linear(in_features=512, out_features=3),
        )
        self.certainty_classifier = nn.Sequential(
            nn.Dropout(p=0.3),
            nn.Linear(in_features=512, out_features=2),
        )
            
    def forward(self, x):
        x = self.feature_extract(x)
        # ë¬¸ì¥ ìœ í˜•, ê·¹ì„±, ì‹œì œ, í™•ì‹¤ì„±ì„ ê°ê° ë¶„ë¥˜
        type_output = self.type_classifier(x)
        polarity_output = self.polarity_classifier(x)
        tense_output = self.tense_classifier(x)
        certainty_output = self.certainty_classifier(x)
        return type_output, polarity_output, tense_output, certainty_output
```   

### ğŸ€ Submission & Score      
ğŸ“Œ Tensorflow : 0.5794        
ğŸ“Œ pytorch(baseline) : 0.5362        
ğŸ“Œ best score : 0.7559 (ëŒ€íšŒê°€ ëë‚˜ì§€ ì•Šì•„ ëª¨ë¸ì€ ë¯¸ê³µê°œ)           

---
